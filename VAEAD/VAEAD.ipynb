{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/Michedev/VAE_anomaly_detection/blob/master/vae_anomaly_detection/VAE.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import f1_score\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import datasets.load_tabular as NAD\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.functional as F\n",
    "import torch.nn.init as weight_init\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrhy_train_X, arrhy_train_y, arrhy_test_X, arrhy_test_y = NAD.Arrhythmia_train_test_split('/home/sewon/anomaly_detection/datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(arrhy_train_X)\n",
    "train = scaler.transform(arrhy_train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "        # self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc_mean = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc_var = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.actf = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h1 = self.actf(self.linear1(x))\n",
    "        mean = self.fc_mean(h1)\n",
    "        log_var = self.fc_var(h1)\n",
    "        \n",
    "        return mean, log_var        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear3 = nn.Linear(latent_dim, hidden_dim)\n",
    "        # self.linear4 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.rc_mean = nn.Linear(hidden_dim, output_dim)\n",
    "        self.rc_var = nn.Linear(hidden_dim, output_dim)\n",
    "        self.actf = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h2 = self.actf(self.linear3(x))\n",
    "        r_mean = self.rc_mean(h2)\n",
    "        r_log_var = self.rc_var(h2)\n",
    "        \n",
    "        return r_mean, r_log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEAD(nn.Module):\n",
    "    def __init__(self, Encoder, Decoder, L = 10):\n",
    "        super(VAEAD, self).__init__()\n",
    "        self.encoder = Encoder\n",
    "        self.decoder = Decoder\n",
    "        self.L = L # number of monte carlo estimates\n",
    "        self.prior = Normal(0,1)\n",
    "        \n",
    "    def reparameterization(self, mu, std):\n",
    "        epsilon = torch.rand_like(std).to(device)\n",
    "        z = mu + std * epsilon\n",
    "        return z\n",
    "    \n",
    "    def forward(self, x):\n",
    "        pred_result = self.predict(x)\n",
    "        x = x.unsqueeze(0)\n",
    "        # log_like = Normal(pred_result['recon_mu'], torch.exp(0.5*pred_result['recon_logvar'])).log_prob(x).mean(\n",
    "        #     dim=0)  # average over sample dimension\n",
    "        log_like = -0.5*(((x.repeat((self.L,1,1)) - pred_result['recon_mu'])**2)/torch.exp(pred_result['recon_logvar']) + \n",
    "                         (torch.log(torch.tensor(2.0*torch.pi)) + pred_result['recon_logvar']))\n",
    "        log_like = log_like.mean(dim=0)\n",
    "        log_like = log_like.mean(dim=0).sum()\n",
    "        kl_div = -0.5 * torch.sum(1 + pred_result['latent_logvar'] - pred_result['latent_mu'].pow(2) - pred_result['latent_logvar'].exp())\n",
    "        loss = kl_div - log_like\n",
    "        return dict(loss = loss, kl_div = kl_div, recon_loss = log_like, **pred_result)\n",
    "        \n",
    "    def predict(self,x):\n",
    "        mu, log_var = self.encoder(x.float())\n",
    "        z_list = []\n",
    "        for i in range(self.L):\n",
    "            z_sample = self.reparameterization(mu, torch.exp(0.5 * log_var))\n",
    "            z_list.append(z_sample)\n",
    "        z_mc = torch.cat(z_list, 0)   # (L x batch_size, latent size) \n",
    "      \n",
    "        recon_mu, recon_logvar = self.decoder(z_mc.float())\n",
    "        recon_mu = recon_mu.view(self.L, *x.shape)\n",
    "        recon_logvar = recon_logvar.view(self.L, *x.shape)\n",
    "        \n",
    "        return dict(latent_mu = mu, latent_logvar = log_var, \n",
    "                    recon_mu = recon_mu, recon_logvar = recon_logvar, z = z_mc)\n",
    "    \n",
    "    \n",
    "    def is_anomaly(self, x, alpha = 0.05):\n",
    "        p = self.reconstruction_prob(x)\n",
    "        return p < alpha\n",
    "    \n",
    "    def reconstruction_prob(self, x):\n",
    "        with torch.no_grad():\n",
    "            pred = self.predict(x)\n",
    "        recon_dist =  Normal(pred['recon_mu'], torch.exp(0.5 * pred['recon_logvar']))\n",
    "        x = x.unsqueeze(0)\n",
    "        p = recon_dist.log_prob(x).exp().mean(dim = 0)\n",
    "        p = p.mean(dim = -1) # vector of shape [batch_size]\n",
    "        return p\n",
    "    \n",
    "            \n",
    "    def generate(self, batch_size, latent_size):\n",
    "        z = self.prior.sample((batch_size, latent_size))\n",
    "        recon_mu, recon_logvar = self.decoder(z.float())\n",
    "        return recon_mu + torch.exp(0.5 * recon_logvar) * torch.rand_like(recon_logvar)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder(arrhy_train_X.shape[1], 400, 200)\n",
    "dec = Decoder(200, 400, arrhy_train_X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAEAD(enc, dec).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training VAE...\n",
      "Epoch [1 / 100] Average Loss:: 20.123727\n",
      "Epoch [2 / 100] Average Loss:: 18.861308\n",
      "Epoch [3 / 100] Average Loss:: 17.793285\n",
      "Epoch [4 / 100] Average Loss:: 16.877999\n",
      "Epoch [5 / 100] Average Loss:: 16.091130\n",
      "Epoch [6 / 100] Average Loss:: 15.416071\n",
      "Epoch [7 / 100] Average Loss:: 14.833265\n",
      "Epoch [8 / 100] Average Loss:: 14.325826\n",
      "Epoch [9 / 100] Average Loss:: 13.881872\n",
      "Epoch [10 / 100] Average Loss:: 13.487742\n",
      "Epoch [11 / 100] Average Loss:: 13.141473\n",
      "Epoch [12 / 100] Average Loss:: 12.822610\n",
      "Epoch [13 / 100] Average Loss:: 12.535174\n",
      "Epoch [14 / 100] Average Loss:: 12.272960\n",
      "Epoch [15 / 100] Average Loss:: 12.026290\n",
      "Epoch [16 / 100] Average Loss:: 11.798085\n",
      "Epoch [17 / 100] Average Loss:: 11.585753\n",
      "Epoch [18 / 100] Average Loss:: 11.383223\n",
      "Epoch [19 / 100] Average Loss:: 11.195696\n",
      "Epoch [20 / 100] Average Loss:: 11.015023\n",
      "Epoch [21 / 100] Average Loss:: 10.848338\n",
      "Epoch [22 / 100] Average Loss:: 10.682636\n",
      "Epoch [23 / 100] Average Loss:: 10.523355\n",
      "Epoch [24 / 100] Average Loss:: 10.377002\n",
      "Epoch [25 / 100] Average Loss:: 10.230274\n",
      "Epoch [26 / 100] Average Loss:: 10.089930\n",
      "Epoch [27 / 100] Average Loss:: 9.949589\n",
      "Epoch [28 / 100] Average Loss:: 9.817696\n",
      "Epoch [29 / 100] Average Loss:: 9.686440\n",
      "Epoch [30 / 100] Average Loss:: 9.553882\n",
      "Epoch [31 / 100] Average Loss:: 9.425679\n",
      "Epoch [32 / 100] Average Loss:: 9.295698\n",
      "Epoch [33 / 100] Average Loss:: 9.174359\n",
      "Epoch [34 / 100] Average Loss:: 9.041055\n",
      "Epoch [35 / 100] Average Loss:: 8.916235\n",
      "Epoch [36 / 100] Average Loss:: 8.793547\n",
      "Epoch [37 / 100] Average Loss:: 8.675533\n",
      "Epoch [38 / 100] Average Loss:: 8.546294\n",
      "Epoch [39 / 100] Average Loss:: 8.420339\n",
      "Epoch [40 / 100] Average Loss:: 8.292012\n",
      "Epoch [41 / 100] Average Loss:: 8.162649\n",
      "Epoch [42 / 100] Average Loss:: 8.037235\n",
      "Epoch [43 / 100] Average Loss:: 7.909929\n",
      "Epoch [44 / 100] Average Loss:: 7.780445\n",
      "Epoch [45 / 100] Average Loss:: 7.652341\n",
      "Epoch [46 / 100] Average Loss:: 7.519105\n",
      "Epoch [47 / 100] Average Loss:: 7.396448\n",
      "Epoch [48 / 100] Average Loss:: 7.268576\n",
      "Epoch [49 / 100] Average Loss:: 7.147430\n",
      "Epoch [50 / 100] Average Loss:: 7.032728\n",
      "Epoch [51 / 100] Average Loss:: 6.921692\n",
      "Epoch [52 / 100] Average Loss:: 6.808601\n",
      "Epoch [53 / 100] Average Loss:: 6.720045\n",
      "Epoch [54 / 100] Average Loss:: 6.633755\n",
      "Epoch [55 / 100] Average Loss:: 6.556738\n",
      "Epoch [56 / 100] Average Loss:: 6.487367\n",
      "Epoch [57 / 100] Average Loss:: 6.431430\n",
      "Epoch [58 / 100] Average Loss:: 6.369522\n",
      "Epoch [59 / 100] Average Loss:: 6.329959\n",
      "Epoch [60 / 100] Average Loss:: 6.268985\n",
      "Epoch [61 / 100] Average Loss:: 6.213550\n",
      "Epoch [62 / 100] Average Loss:: 6.179787\n",
      "Epoch [63 / 100] Average Loss:: 6.138315\n",
      "Epoch [64 / 100] Average Loss:: 6.097874\n",
      "Epoch [65 / 100] Average Loss:: 6.048855\n",
      "Epoch [66 / 100] Average Loss:: 6.009294\n",
      "Epoch [67 / 100] Average Loss:: 5.968381\n",
      "Epoch [68 / 100] Average Loss:: 5.943583\n",
      "Epoch [69 / 100] Average Loss:: 5.904845\n",
      "Epoch [70 / 100] Average Loss:: 5.871822\n",
      "Epoch [71 / 100] Average Loss:: 5.833980\n",
      "Epoch [72 / 100] Average Loss:: 5.799877\n",
      "Epoch [73 / 100] Average Loss:: 5.772828\n",
      "Epoch [74 / 100] Average Loss:: 5.738053\n",
      "Epoch [75 / 100] Average Loss:: 5.712900\n",
      "Epoch [76 / 100] Average Loss:: 5.667931\n",
      "Epoch [77 / 100] Average Loss:: 5.646077\n",
      "Epoch [78 / 100] Average Loss:: 5.609480\n",
      "Epoch [79 / 100] Average Loss:: 5.583425\n",
      "Epoch [80 / 100] Average Loss:: 5.557596\n",
      "Epoch [81 / 100] Average Loss:: 5.519884\n",
      "Epoch [82 / 100] Average Loss:: 5.488418\n",
      "Epoch [83 / 100] Average Loss:: 5.463779\n",
      "Epoch [84 / 100] Average Loss:: 5.437692\n",
      "Epoch [85 / 100] Average Loss:: 5.408006\n",
      "Epoch [86 / 100] Average Loss:: 5.380583\n",
      "Epoch [87 / 100] Average Loss:: 5.361637\n",
      "Epoch [88 / 100] Average Loss:: 5.328400\n",
      "Epoch [89 / 100] Average Loss:: 5.303272\n",
      "Epoch [90 / 100] Average Loss:: 5.275136\n",
      "Epoch [91 / 100] Average Loss:: 5.245407\n",
      "Epoch [92 / 100] Average Loss:: 5.214528\n",
      "Epoch [93 / 100] Average Loss:: 5.193697\n",
      "Epoch [94 / 100] Average Loss:: 5.162919\n",
      "Epoch [95 / 100] Average Loss:: 5.137800\n",
      "Epoch [96 / 100] Average Loss:: 5.118800\n",
      "Epoch [97 / 100] Average Loss:: 5.080559\n",
      "Epoch [98 / 100] Average Loss:: 5.057539\n",
      "Epoch [99 / 100] Average Loss:: 5.033683\n",
      "Epoch [100 / 100] Average Loss:: 5.005520\n",
      "Finish!!\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training VAE...\")\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    overall_loss = 0\n",
    "    for batch_idx, x in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x = x.to(device)\n",
    "        pred = model(x)\n",
    "        loss = pred['loss']\n",
    "        overall_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print('Epoch [%d / %d] Average Loss:: %f' % (epoch+1, epochs, overall_loss / (batch_idx*batch_size)))    \n",
    "    \n",
    "print(\"Finish!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 274)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = scaler.transform(arrhy_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_X = torch.FloatTensor(test)\n",
    "    test_X = test_X.to(device)\n",
    "    recon_prob = model.reconstruction_prob(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5800, 1.7054, 1.5198, 1.7173, 1.6722, 1.6432, 1.5808, 1.5528, 1.6399,\n",
       "        1.6529, 1.6908, 1.5701, 1.6562, 1.6062, 1.6653, 1.7243, 1.6342, 1.5196,\n",
       "        1.6985, 1.6497, 1.6171, 1.6554, 1.6840, 1.6189, 1.6516, 1.6837, 1.6340,\n",
       "        1.6449, 1.6743, 1.6440, 1.6036, 1.6741, 1.4456, 1.6305, 1.7153, 1.7217,\n",
       "        1.6942, 1.6928, 1.6821, 1.6763, 1.6076, 1.5559, 1.6663, 1.7303, 1.6264,\n",
       "        1.3029, 1.5160, 1.7345, 1.6137, 1.6156, 1.6628, 1.6447, 1.7370, 1.6671,\n",
       "        1.5637, 1.4794, 1.6457, 1.5454, 1.6337, 1.5866, 1.4576, 1.0734, 1.5836,\n",
       "        1.5472, 1.6791, 1.5982, 1.6099, 1.5516, 1.4423, 1.6267, 1.4677, 1.5752,\n",
       "        1.6161, 0.9175, 1.3230, 1.6943, 1.5859, 1.6848, 1.3581, 1.6014, 1.4915,\n",
       "        1.5502, 1.4649, 1.6416, 1.7601, 1.6175, 1.7169, 1.6003, 1.5936, 1.5345,\n",
       "        1.6269, 1.5826, 1.5347, 1.6338, 1.4529, 1.6182, 1.6184, 1.4809, 1.6862,\n",
       "        1.6295, 1.7269, 1.6628, 1.6849, 1.6335, 1.7053, 1.4111, 1.7321, 1.5160,\n",
       "        1.6410, 1.6135, 1.5012, 1.0616, 1.6184, 1.6413, 1.5347, 1.6617, 1.6841,\n",
       "        1.6621, 1.2891, 1.6659, 1.6504, 1.2436, 1.5008, 1.6298, 1.6727, 1.7241,\n",
       "        1.5466, 1.6072, 1.6926, 1.6662, 1.6700, 0.4568, 1.6609, 1.7237, 1.6539,\n",
       "        1.6685, 1.5215, 1.5754, 1.5054, 1.6635, 1.5976, 1.6979, 1.5446, 1.6504,\n",
       "        1.7133, 1.6143, 1.7270, 1.6566, 1.6888, 1.6462, 1.6315, 1.6691, 1.5913,\n",
       "        1.5930, 1.6777, 1.6598, 1.4927, 1.6861, 1.6960, 1.6720, 1.6859, 1.5470,\n",
       "        1.6303, 1.6406, 1.6551, 1.7448, 1.6105, 1.6686, 1.4994, 1.6106, 1.6102,\n",
       "        1.5749, 1.4953, 1.6864, 1.5805, 1.6738, 1.6655, 1.6689, 1.6085, 1.6044,\n",
       "        1.7128, 1.6455, 1.5459, 1.6882, 1.6480, 1.7406, 1.6477, 1.7113, 1.6831,\n",
       "        1.4974, 0.7614, 1.5764, 1.7267, 1.4600, 1.6878, 1.6322, 1.6390, 1.4477,\n",
       "        1.5582, 1.6993, 1.5192, 1.3420, 1.6617, 0.8504, 1.6859, 0.4949, 1.5885,\n",
       "        1.2349, 1.2808, 1.4366, 1.7612, 1.7102, 1.5428, 0.6653, 1.6892, 1.5529,\n",
       "        1.5506, 1.5290, 1.6450, 1.5962, 1.3380, 1.0009, 1.1863, 1.6388, 1.5356,\n",
       "        0.8798, 1.4848, 1.5135, 1.5812, 1.6143, 1.5753, 1.3486, 1.4592, 1.1257,\n",
       "        1.6482, 1.5468, 1.4768, 1.3843, 1.7260, 1.0037, 1.4987, 1.1453, 1.6543,\n",
       "        1.3189, 1.2954, 1.2550, 1.6459, 1.6817, 1.4280, 1.6093, 1.0340, 1.3855,\n",
       "        1.5966, 1.4201, 1.1745, 1.6297, 1.6884, 1.4921, 1.4127],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5257142857142858"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(arrhy_test_y, (recon_prob < 1.6).cpu().numpy().astype(int), average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal, kl_divergence\n",
    "from torch.nn.functional import softplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tabular_encoder(input_size: int, latent_size: int):\n",
    "    \"\"\"\n",
    "    Simple encoder for tabular data.\n",
    "    If you want to feed image to a VAE make another encoder function with Conv2d instead of Linear layers.\n",
    "    :param input_size: number of input variables\n",
    "    :param latent_size: number of output variables i.e. the size of the latent space since it's the encoder of a VAE\n",
    "    :return: The untrained encoder model\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_size, 500),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(500, 200),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(200, latent_size * 2)  # times 2 because this is the concatenated vector of latent mean and variance\n",
    "    )\n",
    "\n",
    "\n",
    "def tabular_decoder(latent_size: int, output_size: int):\n",
    "    \"\"\"\n",
    "    Simple decoder for tabular data.\n",
    "    :param latent_size: size of input latent space\n",
    "    :param output_size: number of output parameters. Must have the same value of input_size\n",
    "    :return: the untrained decoder\n",
    "    \"\"\"\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(latent_size, 200),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(200, 500),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(500, output_size * 2)\n",
    "        # times 2 because this is the concatenated vector of reconstructed mean and variance\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAEAnomalyDetection(nn.Module):\n",
    "    def __init__(self, input_size, latent_size, L=10):\n",
    "        super(VAEAnomalyDetection, self).__init__()\n",
    "        self.L = L\n",
    "        self.input_size = input_size\n",
    "        self.latent_size = latent_size\n",
    "        self.encoder = tabular_encoder(input_size, latent_size)\n",
    "        self.decoder = tabular_decoder(latent_size, input_size)\n",
    "        self.prior = Normal(0, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pred_result = self.predict(x)\n",
    "        x = x.unsqueeze(0)  # unsqueeze to broadcast input across sample dimension (L)\n",
    "        log_lik = Normal(pred_result['recon_mu'], pred_result['recon_sigma']).log_prob(x).mean(\n",
    "            dim=0)  # average over sample dimension\n",
    "        log_lik = log_lik.mean(dim=0).sum()\n",
    "        kl = kl_divergence(pred_result['latent_dist'], self.prior).mean(dim=0).sum()\n",
    "        loss = kl - log_lik\n",
    "        return dict(loss=loss, kl=kl, recon_loss=log_lik, **pred_result)\n",
    "\n",
    "    def predict(self, x):\n",
    "        batch_size = len(x)\n",
    "        latent_mu, latent_sigma = self.encoder(x).chunk(2, dim=1) #both with size [batch_size, latent_size]\n",
    "        latent_sigma = softplus(latent_sigma)\n",
    "        dist = Normal(latent_mu, latent_sigma)\n",
    "        z = dist.rsample([self.L])  # shape: [L, batch_size, latent_size]\n",
    "        z = z.view(self.L * batch_size, self.latent_size)\n",
    "        recon_mu, recon_sigma = self.decoder(z).chunk(2, dim=1)\n",
    "        recon_sigma = softplus(recon_sigma)\n",
    "        recon_mu = recon_mu.view(self.L, *x.shape)\n",
    "        recon_sigma = recon_sigma.view(self.L, *x.shape)\n",
    "        return dict(latent_dist=dist, latent_mu=latent_mu,\n",
    "                    latent_sigma=latent_sigma, recon_mu=recon_mu,\n",
    "                    recon_sigma=recon_sigma, z=z)\n",
    "\n",
    "    def is_anomaly(self, x, alpha=0.05):\n",
    "        p = self.reconstructed_probability(x)\n",
    "        return p < alpha\n",
    "\n",
    "    def reconstructed_probability(self, x):\n",
    "        with torch.no_grad():\n",
    "            pred = self.predict(x)\n",
    "        recon_dist = Normal(pred['recon_mu'], pred['recon_sigma'])\n",
    "        x = x.unsqueeze(0)\n",
    "        p = recon_dist.log_prob(x).exp().mean(dim=0).mean(dim=-1)  # vector of shape [batch_size]\n",
    "        return p\n",
    "\n",
    "    def generate(self, batch_size: int=1) -> torch.Tensor:\n",
    "        z = self.prior.sample((batch_size, self.latent_size))\n",
    "        recon_mu, recon_sigma = self.decoder(z).chunk(2, dim=1)\n",
    "        recon_sigma = softplus(recon_sigma)\n",
    "        return recon_mu + recon_sigma * torch.rand_like(recon_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 30\n",
    "model = VAEAnomalyDetection(arrhy_train_X.shape[1], 200, 10).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = arrhy_train_X, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training VAE...\n",
      "\tEpoch 1 complete! \tAverage Loss:  3865.231015625\n",
      "\tEpoch 2 complete! \tAverage Loss:  694.80337890625\n",
      "\tEpoch 3 complete! \tAverage Loss:  344.562509765625\n",
      "\tEpoch 4 complete! \tAverage Loss:  245.24439453125\n",
      "\tEpoch 5 complete! \tAverage Loss:  204.117783203125\n",
      "\tEpoch 6 complete! \tAverage Loss:  165.185107421875\n",
      "\tEpoch 7 complete! \tAverage Loss:  131.065634765625\n",
      "\tEpoch 8 complete! \tAverage Loss:  105.5690380859375\n",
      "\tEpoch 9 complete! \tAverage Loss:  89.9092626953125\n",
      "\tEpoch 10 complete! \tAverage Loss:  79.740888671875\n",
      "\tEpoch 11 complete! \tAverage Loss:  69.49947509765624\n",
      "\tEpoch 12 complete! \tAverage Loss:  60.49935791015625\n",
      "\tEpoch 13 complete! \tAverage Loss:  53.7478564453125\n",
      "\tEpoch 14 complete! \tAverage Loss:  48.09618896484375\n",
      "\tEpoch 15 complete! \tAverage Loss:  43.38744140625\n",
      "\tEpoch 16 complete! \tAverage Loss:  39.5595361328125\n",
      "\tEpoch 17 complete! \tAverage Loss:  36.28773681640625\n",
      "\tEpoch 18 complete! \tAverage Loss:  33.57497192382812\n",
      "\tEpoch 19 complete! \tAverage Loss:  31.10333984375\n",
      "\tEpoch 20 complete! \tAverage Loss:  29.041337890625\n",
      "\tEpoch 21 complete! \tAverage Loss:  27.126324462890626\n",
      "\tEpoch 22 complete! \tAverage Loss:  25.447872314453125\n",
      "\tEpoch 23 complete! \tAverage Loss:  24.48564697265625\n",
      "\tEpoch 24 complete! \tAverage Loss:  23.140877685546876\n",
      "\tEpoch 25 complete! \tAverage Loss:  22.229129638671875\n",
      "\tEpoch 26 complete! \tAverage Loss:  21.300546875\n",
      "\tEpoch 27 complete! \tAverage Loss:  20.70540771484375\n",
      "\tEpoch 28 complete! \tAverage Loss:  19.943558349609376\n",
      "\tEpoch 29 complete! \tAverage Loss:  19.675146484375\n",
      "\tEpoch 30 complete! \tAverage Loss:  18.986322021484376\n",
      "Finish!!\n"
     ]
    }
   ],
   "source": [
    "print(\"Start training VAE...\")\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    overall_loss = 0\n",
    "    for batch_idx, x in enumerate(train_loader):\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        x = x.to(device)\n",
    "        pred = model(x.float())\n",
    "        loss = pred['loss']\n",
    "        overall_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"\\tEpoch\", epoch + 1, \"complete!\", \"\\tAverage Loss: \", overall_loss / (batch_idx*batch_size))\n",
    "    \n",
    "print(\"Finish!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_X = torch.FloatTensor(arrhy_test_X)\n",
    "    test_X = test_X.to(device)\n",
    "    recon_prob = model.reconstructed_probability(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6219, 0.6297, 0.6460, 0.6263, 0.6738, 0.6614, 0.6802, 0.6372, 0.6565,\n",
       "        0.6160, 0.6625, 0.6364, 0.6579, 0.6266, 0.6736, 0.6319, 0.6661, 0.6565,\n",
       "        0.6027, 0.6768, 0.5837, 0.5936, 0.6638, 0.6184, 0.6330, 0.6468, 0.6544,\n",
       "        0.6699, 0.6935, 0.6360, 0.6444, 0.6595, 0.6106, 0.6733, 0.6637, 0.6806,\n",
       "        0.7046, 0.6497, 0.6976, 0.6531, 0.6691, 0.6464, 0.6333, 0.6719, 0.6449,\n",
       "        0.6936, 0.6342, 0.7040, 0.6937, 0.6119, 0.6744, 0.6910, 0.6764, 0.6251,\n",
       "        0.6422, 0.5764, 0.6467, 0.6084, 0.7056, 0.5983, 0.6251, 0.4510, 0.5668,\n",
       "        0.6740, 0.6404, 0.7098, 0.6810, 0.6393, 0.5552, 0.6511, 0.5285, 0.6080,\n",
       "        0.6384, 0.6241, 0.5699, 0.6551, 0.6522, 0.6724, 0.6278, 0.5994, 0.6702,\n",
       "        0.6490, 0.6086, 0.6343, 0.6968, 0.6276, 0.6715, 0.6706, 0.6730, 0.6370,\n",
       "        0.6488, 0.6321, 0.6095, 0.7021, 0.6425, 0.6264, 0.6512, 0.5972, 0.6394,\n",
       "        0.6330, 0.6772, 0.6714, 0.6517, 0.7051, 0.6141, 0.6613, 0.6868, 0.6161,\n",
       "        0.6595, 0.6118, 0.6247, 0.5420, 0.6294, 0.6822, 0.6402, 0.5713, 0.6689,\n",
       "        0.6025, 0.6848, 0.6639, 0.6510, 0.5724, 0.6444, 0.6546, 0.6537, 0.6261,\n",
       "        0.6863, 0.6405, 0.6991, 0.6567, 0.6685, 0.5844, 0.6909, 0.6669, 0.6633,\n",
       "        0.6225, 0.6372, 0.6506, 0.5285, 0.6800, 0.6696, 0.6553, 0.6127, 0.6490,\n",
       "        0.6519, 0.6773, 0.6570, 0.6830, 0.6675, 0.6676, 0.6607, 0.6761, 0.5975,\n",
       "        0.6671, 0.6203, 0.6499, 0.6424, 0.5966, 0.6444, 0.6866, 0.6503, 0.5789,\n",
       "        0.6664, 0.6099, 0.6985, 0.6394, 0.6432, 0.6591, 0.6515, 0.6362, 0.6440,\n",
       "        0.6443, 0.5969, 0.6849, 0.6476, 0.6122, 0.6623, 0.6324, 0.6472, 0.6649,\n",
       "        0.6682, 0.6760, 0.6801, 0.6454, 0.7041, 0.6599, 0.6764, 0.6710, 0.6684,\n",
       "        0.6686, 0.5337, 0.6686, 0.6437, 0.6469, 0.6204, 0.5446, 0.5965, 0.6558,\n",
       "        0.6095, 0.6086, 0.6185, 0.5773, 0.6364, 0.5294, 0.6250, 0.4790, 0.6678,\n",
       "        0.5917, 0.6202, 0.6121, 0.6263, 0.6520, 0.6151, 0.4879, 0.6336, 0.6008,\n",
       "        0.6146, 0.5714, 0.6746, 0.7001, 0.6266, 0.5377, 0.5328, 0.6490, 0.5763,\n",
       "        0.5348, 0.5945, 0.6441, 0.5733, 0.5569, 0.6666, 0.6027, 0.5268, 0.6272,\n",
       "        0.6342, 0.5667, 0.5666, 0.5713, 0.6617, 0.4511, 0.5329, 0.5976, 0.5839,\n",
       "        0.5688, 0.5755, 0.6516, 0.6615, 0.6240, 0.5440, 0.5898, 0.5474, 0.5819,\n",
       "        0.5015, 0.5488, 0.4696, 0.7123, 0.5925, 0.5095, 0.5382],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5952380952380952"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(arrhy_test_y, (recon_prob < 0.63).cpu().numpy().astype(int), average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ecfe56d3cfcd43713b261054a7a1f07197771e57c2df97194a7291eee7dc423"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('venvs': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
